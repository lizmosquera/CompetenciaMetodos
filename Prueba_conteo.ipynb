{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test competencia Métodos Base de datos Conteo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Javier Arturo Rozo Alzate - jarozoa@eafit.edu.co  \n",
    "Alejandro Palacio Vasquez - apalac19@eafit.edu.co  \n",
    "Liceth Cristina Mosquera Galvis - lcmosquerg@eafit.edu.co  \n",
    "Cristian David Muñoz Mora - cdmunozm@eafit.edu.co  \n",
    "Programa: Metodos Estadısticos Avanzados  \n",
    "Docente:Andres Ramirez Hassan - aramir21@eafit.edu.co  \n",
    "12 de octubre de 2019<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Exploratorios de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas para cargar los datos y manipularlos\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Funciones numéricas\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "from numpy import sort\n",
    "import collections\n",
    "import math\n",
    "import operator\n",
    "from scipy import stats\n",
    "from math import ceil\n",
    "import time\n",
    "import random as rnd\n",
    "import statsmodels\n",
    "import pandas_profiling\n",
    " \n",
    "# Graficar\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline\n",
    "\n",
    "# Modelar\n",
    "from collections import OrderedDict\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, cross_val_score,train_test_split\n",
    "from sklearn.metrics import make_scorer,r2_score,mean_squared_error,explained_variance_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,minmax_scale\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from statsmodels.formula.api import poisson, negativebinomial,glm\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar los datos y escoger la variable dependiente\n",
    "datos = pd.read_csv('datacountstudents.csv')\n",
    "datos = datos.iloc[:,1:]\n",
    "Xd = datos.drop(['yC'], axis=1)\n",
    "yd = datos['yC'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar el test y escoger la variable dependiente\n",
    "test = pd.read_csv('testcountstudents.csv')\n",
    "test = test.iloc[:,1:]\n",
    "Xt = test.drop(['yC'], axis=1)\n",
    "yt = test['yC'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres columnas continuas\n",
    "train_C = Xd.select_dtypes(exclude=['int64'])\n",
    "Columns_C = Xd.columns[(Xd.dtypes.values == np.dtype('float64'))]\n",
    "\n",
    "# Estandarizar solo continuas en train\n",
    "Xd_sc = Xd.copy()\n",
    "col_names = Columns_C[0:13]\n",
    "features_tr = Xd_sc[col_names]\n",
    "scaler = StandardScaler().fit(features_tr.values)\n",
    "features_tr = scaler.transform(features_tr.values)\n",
    "Xd_sc[col_names] = features_tr\n",
    "\n",
    "# Estandarizar solo continuas en test\n",
    "Xt_sc = Xt.copy()\n",
    "features_ts = Xt_sc[col_names]\n",
    "features_ts = scaler.transform(features_ts.values)\n",
    "Xt_sc[col_names] = features_ts\n",
    "\n",
    "# Dataframes\n",
    "X_train_sc = pd.concat([Xd_sc], axis=1, sort=False)\n",
    "X_test_sc = pd.concat([Xt_sc], axis=1, sort=False)\n",
    "#X_train_sc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divido los datos para entrenamiento y testeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se construye el modelo con las variables escogidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_model = XGBRegressor(colsample_bytree=0.6, eta=0.3,learning_rate= 0.1,max_depth=3,min_child_weight=1.5\n",
    "                                   , n_estimators=1000,reg_alpha=1e-05,reg_lambda= 0.45, subsample=0.6,seed=42\n",
    "                                   , base_score=0.7 , booster='gbtree' , colsample_bylevel=0.6 , gamma=0.1\n",
    "                                   , max_delta_step=3 , missing=None , n_jobs=1, nthread=None \n",
    "                                   , objective='reg:squarederror', random_state=0, scale_pos_weight=1 , silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['x25','x3','x23','x8']# 'x26','x7','x3','x8'#columns=['x25','x3','x23','x8'] #'x8','x23','x11','x2'\n",
    "# Dataframe y test\n",
    "Xd_m=pd.DataFrame(Xd_sc,columns=columns)\n",
    "Xt_m=pd.DataFrame(Xt_sc,columns=columns)\n",
    "y_t = pd.DataFrame(yt,columns=['yt'])\n",
    "\n",
    "# Ajustar el Modelo\n",
    "selection_model.fit(Xd_m,yd)\n",
    "\n",
    "# Hacer modelo de predicción\n",
    "preds = selection_model.predict(Xt_m)\n",
    "preds=np.round(preds)\n",
    "\n",
    "# DIscretizar la predicción\n",
    "\n",
    "pred= pd.DataFrame(preds,columns=['pred'])\n",
    "\n",
    "#anexar columna evaluando si el modelo predice los ceros como ceros\n",
    "Result1= pd.concat([y_t,pred], axis=1, sort=False)\n",
    "\n",
    "sum=0\n",
    "# columnas convirtiendo los mayores a cero como unos tanto en test como en la predicción\n",
    "Result1['Mayor0_test'] = (Result1['pred']>0).astype(int)\n",
    "Result1['Mayor0_real'] = (Result1['yt']>0).astype(int)\n",
    "Result1['Prueba']= [0]*len(Result1['Mayor0_real'])\n",
    "sum=0\n",
    "for i in range(len(Result1['Mayor0_real'])):\n",
    "    if Result1.Mayor0_real[i]==Result1.Mayor0_test[i]:\n",
    "        Result1['Prueba'][i]=1\n",
    "        sum=sum+1\n",
    "    else: Result1['Prueba'] [i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Explained_variance_score: \",explained_variance_score(yt,pred))\n",
    "print(\"Test 0 y >0: \",sum/len(Result1['Mayor0_real']))\n",
    "print(\"MSE_test:\",(mean_squared_error(yt, pred)))\n",
    "\n",
    "%matplotlib notebook\n",
    "confusion_matrix = pd.crosstab(Result1['Mayor0_test'],Result1['Mayor0_real'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print (confusion_matrix)\n",
    "\n",
    "#sns.heatmap(confusion_matrix)\n",
    "sns.set(font_scale=2)\n",
    "sns.heatmap(confusion_matrix, cmap=\"Blues\", annot=True,annot_kws={\"size\": 20})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(columns)):\n",
    "    v=vif(np.matrix(Xd_m[0:]),i)\n",
    "    print(\"Variance inflation factor for {}: {}\".format(Xd_m.columns[i],round(v,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result1 = Result1.to_csv ('Desktop\\Result1.csv', index = None, header=True)\n",
    "#Result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.plot(range(len(y_t)), y_t, 'r*-', range(len(y_t)), pred, 'bo-')\n",
    "plt.title('Y_test Vs Y_predit')\n",
    "plt.legend(['Real Values', 'Fitted Values'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validación Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargando datos en matriz de XGB\n",
    "columns=['x25','x3','x23','x8']\n",
    "Xt_m==pd.DataFrame(Xt_m,columns=columns)\n",
    "data_dmatrix = xgb.DMatrix(data=Xt_m,label=yt )\n",
    "#obtener los mejores parametros de la iteración\n",
    "params ={'colsample_bytree': 0.6, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1.5, \n",
    "         'n_estimators': 100, 'reg_alpha': 0.75, 'reg_lambda': 0.01, 'subsample': 0.6}\n",
    "#entrenando el modelo\n",
    "xg_reg = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=15)\n",
    "# Validación cruzada del modelo\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=5,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((cv_results[\"test-rmse-mean\"]).tail(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
